\chapter{Solution Design and Implementation}\label{chp:design-and-impl}

\section{Problem Definition}
The purpose of this study is to investigate whether it is possible to predict whether a bug is likely to occur in a given file committed to any source code repository from a number of quality metrics associated with each file. 

\section{Solution Design}\label{sec:design}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Gathered}\label{sec:data-available}
The data collected contained \totalRows{} initially collected in 67 columns. Each record corresponds to a source code file at a given point in time and subsection \ref{sec:data-available} depicts attributes definition through Tables \ref{tbl:available-data-non-repeating-types} to \ref{tbl:available-data-above-0-max-100}, specifying uncommon datatypes found, as well as lists where each attribute in the list has the same properties with regards to data category, data type, and minimum and maximum values present. 

\begin{table}[h!]
\caption{Data Available - non repeating data types}
\label{tbl:available-data-non-repeating-types}
\begin{tabular}{@{}ll@{}}
\toprule
Metric name & Description \\ \midrule
issue key & text \\ 
file path & text \\
source repo & text \\
author & discrete, enumeration of possible authors \\
prev author & discrete, enumeration of possible authors\\
timestamp & continuous, epoch time \\
prev timestamp & continuous, epoch time \\
is bug & boolean, True or False \\
files & ordinal, integer, $\geq{}1$ \\
sqale debt & ratio, integer, $\geq{}0$ \\
statements & ordinal, integer, $\geq{}1$ \\
violations & ratio, integer, $\geq{}0$ \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[h!]
\caption{Ordinal data, integer, min $\geq{}0 \leq{}100$}
\label{tbl:available-data-above-0-max-100}
\begin{tabular}{@{}l@{}}
\toprule
Metric Name \\ \midrule
branch coverage \\
overall branch coverage \\
overall coverage \\
overall line coverage \\
overall uncovered conditions \\
overall uncovered lines \\ \bottomrule
\end{tabular}
\end{table}


\begin{table}[h!]
\caption{Numeric data, integer, min $\geq{}0$, no definitive maximum}
\label{tbl:available-data-above-0-no-max}
\begin{tabular}{@{}ll@{}}
\toprule
Metric Name & Metric Name \\ \midrule
blocker violations & line coverage \\
bugs & lines \\
classes & lines to cover \\
code smells & major violations \\
comment lines & minor violations \\
comment lines density & ncloc \\
complexity & open issues \\
confirmed issues & public documented API density \\
coverage & public undocumented API \\
critical violations & reliability rating \\
duplicated blocks & reliability remediation effort \\
duplicated files & reopened issues \\
duplicated lines & security rating \\
duplicated lines density & security remediation effort \\
effort to reach maintainability rating A & skipped tests \\
false positive issues & SQALE index \\
file complexity & SQALE rating \\
function complexity & test errors \\
functions & test failures \\
generated lines & test success density \\
generated ncloc & uncovered conditions \\
info violations & uncovered lines \\
it coverage & vulnerabilities \\
it line coverage & wont fix issues \\
it uncovered lines &  \\ \bottomrule
\end{tabular}
\end{table}


\subsection{Data Gathering Components}
The dataset for the analysis had to be generated from live business data as such data has not been made available in the public domain. Section \ref{sec:data-available} can be used a reference as to what metrics, along with their type and brief description, have been gathered. In order to construct the dataset subsequently used in the analysis, 3 real live business tools were used:

\begin{enumerate}{\label{lst:tools_used}}
    \item Sonar server by SonarSource - provided code quality metrics
    \item JIRA by Atlassian  - provided information about file commits as well as the classification of commits into "a bug" or "not a bug" categories
    \item Bitbucket by Atlassian  - provided information about commit timestamp, the author as well as details about previous commit author and previous commit timestamp allowing for calculating file staleness 
\end{enumerate}
    
Additionally, a tool to gather metrics, referred to as Data Gatherer, has been developed in order to produce the end dataset and will be made available upon submission. The purpose of the Data Gatherer tool is to coordinate the execution of other tools from the above list as well as collate the acquired data into the end dataset then used in further analysis as per Figure \ref{fig:data_gathering}.

\begin{figure}[h!]
\centering
    \includegraphics{\figpath/data_arch_small.png}
    \caption{Dataset Gathering operations}
    \label{fig:data_gathering}
\end{figure}

First tool to be used in the data gathering process is Atlassian's JIRA server. JIRA is a ticketing system used by software developers to keep track of issues, feature requests and most importantly in the current context, bugs. Each ticket has been assigned a category upon its creation depicting its purpose. In the context of the current use case the most relevant types encountered are:

\begin{itemize}
    \item Story - represents a feature task to be done. Upon completion it is a fully functional, testable vertical slice of functionality delivering value to end-users
    \item Task - represents an additional development task, such as, but not limited to, setting up test environments, automation of effort, including testing effort, infrastructure maintenance etc. Does not provide direct value to end users
    \item Bug - represents issues found in released software, especially when expected and actual behaviour of a given piece of functionality doesn't match.
\end{itemize}
Given that Task type tickets are not directly linked to the development life cycle they have been excluded from further analysis and the focus has been placed on Story and Bug type tickets instead.

The second use of JIRA server was its proprietary integration with the source code repository - Bitbucket, as both tools are offered by the same company, Atlassian. For each of the JIRA tickets there existed a link between a given ticket and source code file changes, or commits, made and persisted in Bitbucket system. 
Each commit could consist of many files and each source code file could have been committed to multiple times under the umbrella of a single ticket. However, not all commit records under a ticket have been taken into the account - every so called merge commit have been excluded.

To illustrate what a merge commit is and why it must be excluded \ref{fig:git-branching-merging-and-rebasing} will be used, where blue nodes signify the master, or the golden copy of the code, and green and purple identify branches, where feature, bug fix or any other development work is carried out as part of a development lifecycle. At the end of its life a branch will be integrated into the Master branch, which will generate a merge commit - illustrated by Feature 1 branch. Additionally, it is a normal occurrence to have more than 1 branch created in a given codebase at any given time. If another branch has been created from the master before Feature 1 code was merged, as per \ref{fig:git-branching-merging-and-rebasing} Feature 2, and it is actively being developed on past the merge point such branch will have to be rebased. The rebase process will pull in the merge commit created by Feature 1, however, all source code files listed under merge commit will have already been analyzed under JIRA ticket representing Feature 1, therefore should it not be excluded from further analysis it would have duplicated the effort. Not excluding merge commits also represented significant risk with regards to story vs. bug categorization of source code files committed as Feature 2 might as well have been a bug. In such scenario file committed under Feature 1 ticked would be categorized as non-bug, as per ticket category, as well as bug as per category assigned by the second ticket.

\todo{Need to change Feature 2 to Bug, to illustrate merge commit exclusion better}
\begin{figure}[!h]
    \centering
    \includegraphics{\figpath/git_branching.png}
    \caption{GIT branching and rebasing strategy}
    \label{fig:git-branching-merging-and-rebasing}
\end{figure}

JIRA ticketing system provided the following columns:
\begin{itemize}
    \item issue key
    \item source repository
    \item file path
    \item category of the record, bug or not a bug
\end{itemize}

while the Bitbucket server provided additional information about:
\begin{itemize}\label{lst:design:info-from-bitbucket}
    \item author
    \item previous author
    \item commit timestamp
    \item timestamp of the previous commit
\end{itemize}

The final tool utilized was SonarQube by SonarSource, an open-source platform. Its capabilities include continuous inspection of code quality to perform automatic reviews with static analysis of code to detect code smells, reports on duplicated code, coding standards, unit tests, code coverage, code complexity, comments,  security vulnerabilities, and much more. In the context of this use case it was utilized to associate code metrics listed in Tables \ref{tbl:available-data-above-0-max-100} and \ref{tbl:available-data-above-0-no-max} as well as \files{}, \sqaleDebt{}, \statements{} and \violations{} provided in Table \ref{tbl:available-data-non-repeating-types}.

The \issueKey{}, \sourceRepository{} and \filePath{} were only used to verify that a given data point can be traced to a relevant JIRA ticket in order to verify it belongs to a assigned category, \authorAttrib{} and \prevAuthorAttrib{} were used to populate seniority and project tenure features. Finally, \timestamp{} and \prevTimestamp{} were used to calculate staleness of the file between changes.

\todo{need a whole SUBSECTION dedicated to specific MACHINE LEARNING MODELS}
\subsection{Machine Learning Models Utilized}

\subsubsection{Logistic Regression}
Logistic regression is a type of a predictive analysis. Logistic regression has been selected as it is considered an appropriate analysis method to be conducted when the target variable is binary. 

\subsubsection{Linear Model Regularization} 
Regularization is defined as introducing an additional term to the loss function, the prediction model, in order to prevent overfitting of same. During the analysis Lasso and Ridge techniques, referred to as L1 and L2 regularization respectively, were used due to the number of features under analysis as both focus on coefficient shrinking, however, Table \ref{tab:regularization_l1_vs_l2} outlines key differences between the two methods, starting with the metrics measured by each.

\begin{table}[h!]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
L1                                                 & L2                                                           \\ \midrule
Sum of weight                                      & Sum of square of weights                                     \\
Sparse outputs                                     & Non-sparse output                                            \\
Built-in feature selection                         & No feature selection                                         \\
High sparsity for highly correlated features       & Even coefficient distribution for highly correlated features \\
Can  interpret models with large feature sets & Main use case is preventing overfitting                      \\ \bottomrule
\end{tabular}
\caption{Summary of L1 vs L2 Regularization Techniques}
\label{tab:regularization_l1_vs_l2}
\end{table}

Both methods perform well in spite of the presence of correlated features: L1 by picking the most significant feature and zeroing the coefficient of the related features effectively excluding them from the prediction model, L2 by ensuring even distribution of the coefficients of the correlated features. 

Lasso stands for Least Absolute Shrinkage and it is defined as $RSS$ $+$ \textalpha{} $*$ (sum of absolute value of weights) or:
\begin{equation}\label{eq_lasso}
\sum^n_{i=1}(\hat{y_i}- y_i)^2 + \alpha \sum^n_{j=0}|w_j|
\end{equation}
where \textalpha{} refers to the factor of the penalty applied to a feature and $w_i$ refers to the weight of the feature\cite{Hastie2009SpringerOfLasso}.

Ridge regression works by adding a penalty factor to square of the magnitude of coefficients\cite{Hastie2009SpringerOfRidge}. It can be represented as:
\begin{equation}\label{eq_ridge}
\sum^n_{i=1}(\hat{y_i}- y_i)^2 + \alpha \sum^n_{j=0}w_j^2
\end{equation}
From the same definition it can be deducted that impact of \textalpha{} will be the same is both methods, namely:
\begin{enumerate}\label{list:impact-of-alpha}
\itemsep0em
\item\label{it:item1} $\alpha = 0$, is the same as linear regression, 
\item\label{it:item2} $\alpha = \infty$, the coefficients will be zero due to the infinite weighting on square coefficients anything less than 0 will make the objective infinite
\item\label{it:item3} $0 < \alpha < \infty$, the coefficients will be found between 0 and the ones obtained from a simple linear regression
\end{enumerate}

\subsubsection{Decision Tree Classifier}

\subsection{Data Modelling}

Once a dataset has been generated as per section \ref{sec:design} it underwent the following operations:
\begin{enumerate}\label{lst:dataset-ops}
    \item missing data analysis and data cleaning \label{lst:dataset-ops.item:data-cleaning}
    \item balance of bug to non-bug records in the dataset \label{lst:dataset-ops.item:bug-to-non-bug-balance}
    \item outlier analysis \label{lst:dataset-ops.item:outliers}
    \item data correlation analysis \label{lst:dataset-ops.item:data-correlation}
    \item feature transformation \label{lst:dataset-ops.item:feature-transformation}
    \item feature scaling \label{lst:dataset-ops.item:data-scaling}
    \item relevant feature selection \label{lst:dataset-ops.item:feature-selection}
    \item distribution of selected features \label{lst:dataset-ops.item:attribute-distribution}
    \item evaluation of regularized Logistic Regression model \label{lst:dataset-ops.item:ml-logistic-regression}
    \item evaluation of Decision Tree Classification model \label{lst:dataset-ops.item:ml-decision-tree}
    \item evaluation of additional models as necessary \label{lst:dataset-ops.item:ml-models-additional}
\end{enumerate}

Item \ref{lst:dataset-ops.item:data-cleaning} focuses on cleaning and imputing values for missing metrics. Item \ref{lst:dataset-ops.item:bug-to-non-bug-balance} will focus on listing the ratios between bug and non bug records in the dataset.
Item \ref{lst:dataset-ops.item:outliers} identifies if there are any projects or individual files that are diverging significantly from the rest of the dataset. 
Item \ref{lst:dataset-ops.item:data-correlation} focuses on identifying any feature correlation patterns in order to proceed with feature selection - item  \ref{lst:dataset-ops.item:feature-selection} after which it will be necessary to check for the balance and distribution of the selected features or attributes - which will be the focus of item \ref{lst:dataset-ops.item:attribute-distribution}. Feature distribution is included as part of the analysis as Logistic Regression model is susceptible to non-normally distributed datasets.
Item \ref{lst:dataset-ops.item:data-scaling} concentrates on evaluating multiple scaling methods with regards to their effectiveness of bringing the dataset values to the same scale of magnitude. The scaling method taken into the account are:
\begin{enumerate}
    \item Transformation using natural logarithm - $log(e)$ 
    \item Min-Max scaling
    \item Max-Abs scaling
    \item Standard scaling
    \item Power Transformation using Yeo-Johnson variant
    \item Quantile Transformation using uniform distribution variant
    \item Quantile Transformation using normal distribution variant
\end{enumerate}

\todo{Probably need to talk a bit about what each scaler does and how it works. However, maybe it's better served in the implementation section}
Finally, an evaluation of the effectiveness of selected machine learning models with regards to predicting bug vs non-bug classes in the dataset will be carried out and constitutes the focus of items \ref{lst:dataset-ops.item:ml-logistic-regression}, \ref{lst:dataset-ops.item:ml-decision-tree} and \ref{lst:dataset-ops.item:ml-models-additional} respectively.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation}\label{sec:implementation}
The implementation has been carried out in two steps. In the first step, a tool has been developed in Python language for the purpose of gathering the data required for the analysis - the process is outlined in Section \ref{sec:impl-data-gatherer}. Secondly, the data has been analyzed, in accordance with steps defined in Section \ref{sec:design}, List \ref{lst:dataset-ops}, using Jupyter Notebook tooling, which is the topic of Section \ref{sec:impl-data-analysis}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{Chapters/03a-gatherer-implementation.tex}

\input{Chapters/03b-data-analysis-implementation.tex}

\input{Chapters/03c-scalers-impl.tex}
\input{Chapters/03d-logitstic-regression-impl.tex}
\input{Chapters/03e-decision-tree-impl.tex}
