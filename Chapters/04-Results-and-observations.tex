\chapter{Results and Observations}\label{chp:results-and-observations}
\section{Logistic Regression Results}\label{sec:results:log-reg}
% \todo{Need to Speak to why decision tree results were so much better than those of logistic regression}

\todo{- What are the results in, F1? TF/TP, RSS?}
Due to the implementation specification of the Logistic Regression algorithm forcing L2 regularization upon model by default it was not possible to obtain non-regularized results for comparison.

The scoring function provided by the underlying implementation of the Sci-Kit Learn library used defines it as the mean accuracy of correctly predicting the target value ($y$) for a given set of features ($X$). It is presented as a decimal number in the range of $ 0 to 1$, however, for the purpose of defining it as percentage value all scores from underlying models have been multiplied by $100\%$.

The results for the analysis of both up-sampled and down-sampled datasets, as well as L1 and L2 regularization methods have been compiled into Table \ref{tbl:results:log-reg}. From same it can be observed that the probability of a valid classification of \isBug{} target variable is between 50.4\% - 63.9\% between different scaling methods used to normalize given data.

On average the dataset where the upsampling method was used to achieve class balance has provided better results. It is expected that the smaller number of features exhibiting skewed distribution, as per Section \ref{sec:impl-data-analysis:feature-dist-after-scaling}, had an impact on that. It should also be noted that the difference in accuracy between upsampled and downsampled datasets, for equivalent scalers, has been up to $\approx 3.8\%$.

From regularization point of view, L2 was more successful on average.

The probability of class 0 and 1 class, corresponding to a given file being a bug or not, has been consistently averaged at 50\% for each class across all datasets, normalization and regularization methods. 
\begin{table}[h!]
\centering
\caption{Logistic Regression Results}
\label{tbl:results:log-reg}
\begin{tabular}{@{}lllll@{}}
\toprule
 & Up L1 & Down L1 & Up L2 & Down L2 \\ \midrule
unmodified & 58.8 & 58.8 & 56.3 & 55.8 \\
min-max & 53.9 & 51.5 & 55.0 & 57.4 \\
max-abs & 52.8 & 54.4 & 50.9 & 50.4 \\
standard & 54.7 & 53.6 & 54.4 & 58.2 \\
power-yeo-johnson & 61.7 & 63.1 & 63.9 & 63.6 \\
quantile-normal & 53.6 & 56.3 & 60.4 & 61.7 \\
quantile-uniform & 60.9 & 57.1 & 62.5 & 62.5 \\ \bottomrule
\end{tabular}
\end{table}

\section{Decision Tree Results}\label{sec:results:decision-tree}
The results of decision tree classification have been compiled into Table \ref{tbl:results:decision-tree}. From same it can be observed, that similarly to Logistic Regression results in section \ref{sec:results:log-reg}, the upsampled dataset exhibits higher prediction scores. 

The results of the classification analysis would vary from approximately 86\% to just above 88\% for the downsampled dataset and reaching a staggering approximately 99\% accuracy in the upsampled dataset.
\begin{table}[h!]
\centering
\caption{Decision Tree Classification Results}
\label{tbl:results:decision-tree}
\begin{tabular}{@{}lll@{}}
\toprule
Method Name & Upsampled Score & Downsampled Score \\ \midrule
unmodified & 99.59 & 85.98 \\
min-max & 99.25 & 86.79 \\
max-abs & 99.37 & 88.14 \\
standard & 99.52 & 87.06 \\
power-yeo-johnson & 99.74 & 87.6 \\
quantile-normal & 99.66 & 87.87 \\
quantile-uniform & 99.37 & 87.6 \\ \bottomrule
\end{tabular}
\end{table}

\section{Comparison of model results}
From the results compiled for individual models, sections \ref{sec:results:log-reg}-\ref{sec:results:decision-tree}, it is clearly visible that the Decision Tree Classifier was significantly more successful at generating accurate predictions. It comes expected, as the decision tree model has been proven out to be very successful in analyzing datasets with high feature collinearity \cite{Bertsimas2017Cart} such as this one. 

It has been consciously decided against redistributing the data before applying the Logistic Regression model. It is expected that this decision had an impact on the results of the linear model, which by its definition would perform better should all data be more normally distributed. It should be noted, as discussed in detail in Section \ref{sec:impl-data-analysis:feature-dist}, that in general the skewness of the data while present was not significant in most features.