@misc{fowlerOnMicroservices,
	author = "Fowler, Martin",
    title = "Microservices - a definition of this new architectural term",
    year = "2014",
    url = "https://martinfowler.com/articles/microservices.html"
}

@misc{costOfBugInRelationToDevelopmentPhase,
	author = {{Raygun Incorporated}},
    title = "How much could software errors be costing your company?",
    year = "2017",
    url = "https://raygun.com/blog/cost-of-software-errors"    
}
@article{dragoniOnMs,
	author = "Dragoni, Nicola and Giallorenzo, Saverio and Lafuente, Alberto Lluch and Mazzara, Manuel and Montesi, Fabrizio and Mustafin, Ruslan and Safina, Larisa",
    title = "Microservices: yesterday, today, and tomorrow",
    url = "https://arxiv.org/abs/1606.04036",
    year = "2016"
}

@INPROCEEDINGS{softwareSecurityMentionMicroservice, 
author={Sung Kim and F. B. Bastani and I-Ling Yen and Ing-Ray Chen}, 
booktitle={14th International Symposium on Software Reliability Engineering, 2003. ISSRE 2003.}, 
title={High-assurance synthesis of security services from basic microservices}, 
year={2003}, 
volume={}, 
number={}, 
pages={154-165}, 
keywords={Internet;certification;electronic mail;formal verification;object-oriented programming;security of data;Internet;component security certification;computer hackers;computer network security;computer systems;computer threats;e-mail application;information misusage;malicious attacks;malicious code embedding;microservices;monolithic software system;security service synthesis;software bugs;system security;Computer bugs;Computer hacking;Computer networks;Computer security;Data security;Embedded software;Explosives;Information security;Internet;Software systems}, 
doi={10.1109/ISSRE.2003.1251039}, 
ISSN={1071-9458}, 
month={Nov},}

@INPROCEEDINGS{understandingOfMicroservices, 
author={D. Shadija and M. Rezai and R. Hill}, 
booktitle={2017 23rd International Conference on Automation and Computing (ICAC)}, 
title={Towards an understanding of microservices}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-6}, 
keywords={Internet of Things;Web services;business data processing;service-oriented architecture;Internet of Things;SOA;business analysts;domain driven design;enterprise architects;microservices architecture;service oriented architecture;Business;Computer architecture;Data models;Internet of Things;Service-oriented architecture;Domain Driven Design (DDD);Service Oriented Architecture (SOA);Software Engineering;microservices}, 
doi={10.23919/IConAC.2017.8082018}, 
ISSN={}, 
month={Sept},

}@ARTICLE{studiesOnFaultPrediction, 
author={T. Hall and S. Beecham and D. Bowes and D. Gray and S. Counsell}, 
journal={IEEE Transactions on Software Engineering}, 
title={A Systematic Literature Review on Fault Prediction Performance in Software Engineering}, 
year={2012}, 
volume={38}, 
number={6}, 
pages={1276-1304}, 
abstract={Background: The accurate prediction of where faults are likely to occur in code can help direct test effort, reduce costs, and improve the quality of software. Objective: We investigate how the context of models, the independent variables used, and the modeling techniques applied influence the performance of fault prediction models. Method: We used a systematic literature review to identify 208 fault prediction studies published from January 2000 to December 2010. We synthesize the quantitative and qualitative results of 36 studies which report sufficient contextual and methodological information according to the criteria we develop and apply. Results: The models that perform well tend to be based on simple modeling techniques such as Naive Bayes or Logistic Regression. Combinations of independent variables have been used by models that perform well. Feature selection has been applied to these combinations when models are performing particularly well. Conclusion: The methodology used to build models seems to be influential to predictive performance. Although there are a set of fault prediction studies in which confidence is possible, more studies are needed that use a reliable methodology and which report their context, methodology, and performance comprehensively.}, 
keywords={Bayes methods;regression analysis;software fault tolerance;software quality;contextual information;cost reduction;fault prediction models;fault prediction performance;fault prediction study;feature selection;independent variables;logistic regression;methodological information;naive Bayes;predictive performance;reliable methodology;simple modeling techniques;software engineering;software quality;systematic literature review;Analytical models;Context modeling;Data models;Fault diagnosis;Predictive models;Software testing;Systematics;Systematic literature review;software fault prediction}, 
doi={10.1109/TSE.2011.103}, 
ISSN={0098-5589}, 
month={Nov},}

@INPROCEEDINGS{autoDetectionOfPerfBugs, 
author={S. Tsakiltsidis and A. Miranskyy and E. Mazzawi}, 
booktitle={2016 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
title={On Automatic Detection of Performance Bugs}, 
year={2016}, 
volume={}, 
number={}, 
pages={132-139}, 
abstract={Context: Software performance is a critical non-functional requirement, appearing in many fields such as mission critical applications, financial, and real time systems. In this work we focused on early detection of performance bugs, our software under study was a real time system used in the mobile advertisement / marketing domain. Goal: Find a simple and easy to implement solution, predicting performance bugs. Method: We built several models using four machine learning methods, commonly used for defect prediction: C4.5 Decision Trees, Naive Bayes, Bayesian Networks, and Logistic Regression. Results: Our empirical results show that a C4.5 model, using lines of code changed, file's age and size as explanatory variables, can be used to predict performance bugs (recall = 0.73, accuracy = 0.85, and precision = 0.96). We show that reducing the number of changes delivered on a commit, can decrease the chance of performance bug injection. Conclusions: We believe that our approach can help practitioners to eliminate performance bugs early in the development cycle. Our results are also of interest to theoreticians, establishing a link between functional bugs and (non-functional) performance bugs, and explicitly showing that attributes used for prediction of functional bugs can be used for prediction of performance bugs.}, 
keywords={Bayes methods;belief networks;decision trees;learning (artificial intelligence);program debugging;real-time systems;regression analysis;software performance evaluation;Bayesian networks;C4.5 decision trees;Naive Bayes method;automatic performance bug detection;defect prediction;development cycle;explanatory variables;functional bugs;logistic regression;machine learning methods;marketing domain;mobile advertisement;performance bug elimination;performance bug injection;real time system;software performance;Computer bugs;Computer languages;Mobile communication;Predictive models;Real-time systems;Software;Testing;Mobile Advertisement;Performance Bugs;Performance Optimization;Quality Assurance;Software Faults}, 
doi={10.1109/ISSREW.2016.43}, 
ISSN={}, 
month={Oct},}

@INPROCEEDINGS{bugDetectionInParticleSwarm, 
author={A. Reungsinkonkarn and P. Apirukvorapinit}, 
booktitle={2015 6th International Conference on Intelligent Systems, Modelling and Simulation}, 
title={Bug Detection Using Particle Swarm Optimization with Search Space Reduction}, 
year={2015}, 
volume={}, 
number={}, 
pages={53-57}, 
abstract={A bug detection tool is an important tool in software engineering development. Many research papers have proposed techniques for detecting software bug, but there are certain semantic bugs that are not easy to detect. In our views, a bug can occur from incorrect logics that when a program is executed with a particular input, the program will behave in unexpected ways. In this paper, we propose a method and tool for software bugs detection by finding such input that causes an unexpected output guided by the fitness function. The method uses a Hierarchical Similarity Measurement Model (HSM) to help create the fitness function to examine a program behavior. Its tool uses Particle Swarm Optimization (PSO) with Search Space Reduction (SSR) to manipulate input by contracting and eliminating unfavorable areas of input search space. The programs under experiment were selected from four different domains such as financial, decision support system, algorithms and machine learning. The experimental result shows a significant percentage of success rate up to 93% in bug detection, compared to an estimated success rate of 28% without SSR.}, 
keywords={particle swarm optimisation;program debugging;search problems;software engineering;HSM;PSO;SSR;bug detection tool;fitness function;hierarchical similarity measurement model;input search space;particle swarm optimization;program behavior;search space reduction;software bug detection;software engineering development;Atmospheric measurements;Complexity theory;Computational modeling;Computer bugs;Particle measurements;Particle swarm optimization;Software;Bug Detection;Fitness Function;Hierarchical Similarity Measurement Model (HSM);Optimization;Particle Swarm Optimization (PSO)}, 
doi={10.1109/ISMS.2015.20}, 
ISSN={2166-0662}, 
month={Feb},}

@INPROCEEDINGS{duplicateBugDetection, 
author={J. Deshmukh and A. K. M and S. Podder and S. Sengupta and N. Dubash}, 
booktitle={2017 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
title={Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques}, 
year={2017}, 
volume={}, 
number={}, 
pages={115-124}, 
abstract={Duplicate Bug Detection is the problem of identifying whether a newly reported bug is a duplicate of an existing bug in the system and retrieving the original or similar bugs from the past. This is required to avoid costly rediscovery and redundant work. In typical software projects, the number of duplicate bugs reported may run into the order of thousands, making it expensive in terms of cost and time for manual intervention. This makes the problem of duplicate or similar bug detection an important one in Software Engineering domain. However, an automated solution for the same is not quite accurate yet in practice, in spite of many reported approaches using various machine learning techniques. In this work, we propose a retrieval and classification model using Siamese Convolutional Neural Networks (CNN) and Long Short Term Memory (LSTM) for accurate detection and retrieval of duplicate and similar bugs. We report an accuracy close to 90% and recall rate close to 80%, which makes possible the practical use of such a system. We describe our model in detail along with related discussions from the Deep Learning domain. By presenting the detailed experimental results, we illustrate the effectiveness of the model in practical systems, including for repositories for which supervised training data is not available.}, 
keywords={feedforward neural nets;information retrieval;learning (artificial intelligence);pattern classification;program debugging;software development management;CNN;Deep Learning domain;Deep Learning techniques;Duplicate Bug Detection;LSTM;Long Short Term Memory;Siamese Convolutional Neural Networks;Software Engineering domain;accurate detection;classification model;costly rediscovery;duplicate Bug retrieval;existing bug;machine learning techniques;newly reported bug;original bugs;redundant work;similar bug detection;supervised training data;typical software projects;Computational modeling;Computer bugs;Machine learning;Neural networks;Sun;Training;Convolutional Neural Networks;Deep Learning;Duplicate Bug Detection;Information Retrieval;Long Short Term Memory;Natural Language Processing;Siamese Networks;Word Embeddings}, 
doi={10.1109/ICSME.2017.69}, 
ISSN={}, 
month={Sept},}

@INPROCEEDINGS{reopenedBugsAndMaintenence, 
author={E. Shihab and A. Ihara and Y. Kamei and W. M. Ibrahim and M. Ohira and B. Adams and A. E. Hassan and K. i. Matsumoto}, 
booktitle={2010 17th Working Conference on Reverse Engineering}, 
title={Predicting Re-opened Bugs: A Case Study on the Eclipse Project}, 
year={2010}, 
volume={}, 
number={}, 
pages={249-258}, 
abstract={Bug fixing accounts for a large amount of the software maintenance resources. Generally, bugs are reported, fixed, verified and closed. However, in some cases bugs have to be re-opened. Re-opened bugs increase maintenance costs, degrade the overall user-perceived quality of the software and lead to unnecessary rework by busy practitioners. In this paper, we study and predict re-opened bugs through a case study on the Eclipse project. We structure our study along 4 dimensions: (1) the work habits dimension (e.g., the weekday on which the bug was initially closed on), (2) the bug report dimension (e.g., the component in which the bug was found) (3) the bug fix dimension (e.g., the amount of time it took to perform the initial fix) and (4) the team dimension (e.g., the experience of the bug fixer). Our case study on the Eclipse Platform 3.0 project shows that the comment and description text, the time it took to fix the bug, and the component the bug was found in are the most important factors in determining whether a bug will be re-opened. Based on these dimensions we create decision trees that predict whether a bug will be re-opened after its closure. Using a combination of our dimensions, we can build explainable prediction models that can achieve 62.9% precision and 84.5% recall when predicting whether a bug will be re-opened.}, 
keywords={decision trees;program debugging;software maintenance;decision trees;eclipse project;software maintenance resource;team dimension;text description;Accuracy;Computer bugs;Data mining;Databases;Decision trees;Predictive models;Software;Re-opened bugs;software quality}, 
doi={10.1109/WCRE.2010.36}, 
ISSN={1095-1350}, 
month={Oct},}

@ARTICLE{softwareTestingChallenges, 
author={D. R. Kuhn and D. R. Wallace and A. M. Gallo}, 
journal={IEEE Transactions on Software Engineering}, 
title={Software fault interactions and implications for software testing}, 
year={2004}, 
volume={30}, 
number={6}, 
pages={418-421}, 
abstract={Exhaustive testing of computer software is intractable, but empirical studies of software failures suggest that testing can in some cases be effectively exhaustive. We show that software failures in a variety of domains were caused by combinations of relatively few conditions. These results have important implications for testing. If all faults in a system can be triggered by a combination of n or fewer parameters, then testing all n-tuples of parameters is effectively equivalent to exhaustive testing, if software behavior is not dependent on complex event sequences and variables have a small set of discrete values.}, 
keywords={failure analysis;program testing;software fault tolerance;statistical analysis;computer software testing;discrete value;event sequence;software behavior;software failure;statistical method;test design;Databases;Drugs;Embedded system;Fault detection;History;Microwave ovens;Software quality;Software testing;System testing;65;Statistical methods;test design.;testing strategies}, 
doi={10.1109/TSE.2004.24}, 
ISSN={0098-5589}, 
month={June},}

@inproceedings{Zhou_2012_whereShouldBugsBeFixed,
 author = {Zhou, Jian and Zhang, Hongyu and Lo, David},
 title = {Where Should the Bugs Be Fixed? - More Accurate Information Retrieval-based Bug Localization Based on Bug Reports},
 booktitle = {Proceedings of the 34th International Conference on Software Engineering},
 series = {ICSE '12},
 year = {2012},
 isbn = {978-1-4673-1067-3},
 location = {Zurich, Switzerland},
 pages = {14--24},
 numpages = {11},
 url = {http://dl.acm.org/citation.cfm?id=2337223.2337226},
 acmid = {2337226},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
} 